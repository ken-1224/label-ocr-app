import re
import unicodedata
import streamlit as st
import easyocr
import numpy as np
from PIL import Image, ImageOps
import gspread
from google.oauth2.service_account import Credentials
from datetime import date

# ---------------- åŸºæœ¬è¨­å®š ----------------
st.set_page_config(page_title="å®¶é›»å›åãƒ»ãƒ©ãƒ™ãƒ«èª­å–ï¼ˆã‚«ãƒ¡ãƒ©ãƒ»è¤‡æ•°æ’®å½±å¯¾å¿œï¼‰", page_icon="ğŸ“·")
st.title("å®¶é›»å›åç®¡ç†ã‚¢ãƒ—ãƒª")

# ---------------- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ– ----------------
if "shots" not in st.session_state:
    st.session_state["shots"] = []   # [{"img": PIL.Image, "ocr": "..."}]
if "cam_key" not in st.session_state:
    st.session_state["cam_key"] = 0  # camera_input ã‚’å†ãƒã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã®ã‚­ãƒ¼
if "autofill_enabled" not in st.session_state:
    st.session_state["autofill_enabled"] = True  # OCRè‡ªå‹•åæ˜ ã®ON/OFF

# å…¥åŠ›æ¬„ã®åˆæœŸå€¤
for k, v in {
    "pickup_date": date.today(),
    "warehouse_choice": "æœ¬ç¤¾å€‰åº«ï¼ˆæ±äº¬ï¼‰",
    "warehouse_other": "",
    "maker": "",
    "model": "",
    "serial": "",
    "year": "",
    "note": "",
}.items():
    st.session_state.setdefault(k, v)

DEFAULTS = {
    "pickup_date": date.today(),
    "warehouse_choice": "æœ¬ç¤¾å€‰åº«ï¼ˆæ±äº¬ï¼‰",
    "warehouse_other": "",
    "maker": "",
    "model": "",
    "serial": "",
    "year": "",
    "note": "",
}

def _apply_defaults():
    # å…¥åŠ›æ¬„ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’é©ç”¨
    for k, v in DEFAULTS.items():
        st.session_state[k] = v
    # æ’®å½±ãƒ‡ãƒ¼ã‚¿ã‚‚ãƒªã‚»ãƒƒãƒˆ
    st.session_state["shots"] = []
    st.session_state["cam_key"] += 1

# ã€Œæ¬¡ã®å®Ÿè¡Œã§ãƒªã‚»ãƒƒãƒˆã€ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ãŸã‚‰ã€ã“ã“ã§åˆæœŸåŒ–ã—ã¦ãƒ•ãƒ©ã‚°ã‚’ä¸‹ã‚ã™
if st.session_state.get("_reset_pending", False):
    _apply_defaults()
    st.session_state["_reset_pending"] = False

# ---------------- Google ã‚·ãƒ¼ãƒˆæ¥ç¶š ----------------
@st.cache_resource
def get_sheet():
    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]
    if "gcp_service_account" not in st.secrets:
        raise RuntimeError("Streamlit Secrets ã« [gcp_service_account] ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    sa_raw = st.secrets["gcp_service_account"]
    sa_info = {k: (str(v) if v is not None else "") for k, v in sa_raw.items()}
    creds = Credentials.from_service_account_info(sa_info, scopes=scopes)
    gc = gspread.authorize(creds)

    sheet_id = st.secrets.get("SHEET_ID", "").strip()
    if sheet_id:
        sh = gc.open_by_key(sheet_id)
    else:
        sheet_title = st.secrets.get("SHEET_TITLE", "å®¶é›»å›åç®¡ç†").strip()
        sh = gc.open(sheet_title)
    return sh.sheet1

sheet = None
try:
    sheet = get_sheet()
except Exception as e:
    st.warning("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è¨­å®šå¾Œã«å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
    st.caption(f"è©³ç´°: {e}")

# ---------------- OCR Readerï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ ----------------
@st.cache_resource
def get_reader():
    return easyocr.Reader(["ja", "en"], gpu=False)

reader = get_reader()

# ---------------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼šOCRãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ï¼†æŠ½å‡º ----------------
def _normalize(s: str) -> str:
    # å…¨è§’â†’åŠè§’ã€çµåˆæ–‡å­—ã®çµ±ä¸€
    return unicodedata.normalize("NFKC", s)

def _split_lines(text: str):
    return [ln.strip() for ln in _normalize(text).splitlines() if ln.strip()]

# ---- OCRã‚†ã‚‰ãè£œæ­£ï¼ˆæ–‡è„ˆä¾å­˜ã®ç½®æ›ã¯æ§ãˆã‚ã«ï¼‰----
def _fix_confusions_for_model(tok: str) -> str:
    # ãƒ¢ãƒ‡ãƒ«ã¯è‹±æ•°æ··åœ¨ãŒå‰æï¼šæ•°å­—å‘¨è¾ºã®Oâ†’0ã€Iâ†’1ã€Zâ†’2ã€Sâ†’5ã€Bâ†’8 ã‚’è»½ã‚ã«
    t = tok
    t = re.sub(r'(?<=\d)O|O(?=\d)', '0', t)
    t = re.sub(r'(?<=\d)I|I(?=\d)|l(?=\d)|(?<=\d)l', '1', t)
    t = re.sub(r'(?<=\d)Z|Z(?=\d)', '2', t)
    t = re.sub(r'(?<=\d)S|S(?=\d)', '5', t)
    t = re.sub(r'(?<=\d)B|B(?=\d)', '8', t)
    return t

def _fix_confusions_for_serial(tok: str) -> str:
    # é€£ç¶šæ•°å­—ãƒ»ãƒã‚¤ãƒ•ãƒ³æ¯”ç‡ãŒé«˜ã„å ´åˆã®ã¿å¼·ã‚ã«è£œæ­£
    digits_ratio = sum(c.isdigit() for c in tok) / max(1, len(tok))
    if digits_ratio >= 0.4:
        t = tok
        t = t.replace('O', '0').replace('o', '0')
        t = t.replace('I', '1').replace('l', '1')
        t = t.replace('Z', '2')
        t = t.replace('S', '5')
        t = t.replace('B', '8')
        return t
    return tok

# ---- å¹´å¼ï¼šå’Œæš¦/è¥¿æš¦/æ›¸å¼ã‚†ã‚‰ãå¯¾å¿œ ----
def _to_western_year(era: str, y: int) -> int:
    base = {"ä»¤å’Œ": 2018, "å¹³æˆ": 1988, "æ˜­å’Œ": 1925,
            "R": 2018, "H": 1988, "S": 1925}.get(era, None)
    return base + y if base else 0

def _parse_year(text: str) -> str:
    norm = _normalize(text)

    # 1) ã€Œè£½é€ å¹´/è£½é€ å¹´æœˆ/å¹´å¼ã€å„ªå…ˆ
    m = re.search(r'(è£½é€ å¹´(?:æœˆ)?|å¹´å¼)\s*[:ï¼š]?\s*(\d{4})\s*å¹´?', norm)
    if m:
        return m.group(2)

    # 2) å’Œæš¦ï¼ˆä»¤å’Œ/å¹³æˆ/æ˜­å’Œ + å¹´ï¼‰
    m = re.search(r'(ä»¤å’Œ|å¹³æˆ|æ˜­å’Œ)\s*([å…ƒ\d]{1,2})\s*å¹´', norm)
    if m:
        y = 1 if m.group(2) == "å…ƒ" else int(m.group(2))
        return str(_to_western_year(m.group(1), y))

    # 3) çœç•¥è¨˜å·ï¼ˆR/H/S + æ•°å­—ï¼‰
    m = re.search(r'\b([RHS])\s*([1-3]?\d)\b', norm)
    if m:
        return str(_to_western_year(m.group(1), int(m.group(2))))

    # 4) 4æ¡è¥¿æš¦ï¼ˆ2010ã€œæ¥å¹´ï¼‰
    this_year = date.today().year
    for y in re.findall(r'\b(19\d{2}|20[0-3]\d)\b', norm):
        yi = int(y)
        if 2010 <= yi <= this_year + 1:
            return y

    # 5) ã€Œ2015/07ã€ã€Œ2015-07ã€ãªã©ã‹ã‚‰å¹´ã ã‘æ‹¾ã†
    m = re.search(r'\b(19\d{2}|20[0-3]\d)[/\-\.](0?[1-9]|1[0-2])\b', norm)
    if m:
        return m.group(1)

    return ""

# ---- ãƒ¡ãƒ¼ã‚«ãƒ¼ï¼šåˆ¥åè¾æ›¸æ‹¡å…… ----
_MAKER_TABLE = [
    ("Panasonic", ["PANASONIC", "ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯"]),
    ("Hitachi", ["HITACHI", "æ—¥ç«‹"]),
    ("Toshiba", ["TOSHIBA", "æ±èŠ"]),
    ("Sharp", ["SHARP", "ã‚·ãƒ£ãƒ¼ãƒ—"]),
    ("Sony", ["SONY", "ã‚½ãƒ‹ãƒ¼"]),
    ("Mitsubishi", ["MITSUBISHI", "ä¸‰è±"]),
    ("Hisense", ["HISENSE", "ãƒã‚¤ã‚»ãƒ³ã‚¹"]),
    ("Haier", ["HAIER", "ãƒã‚¤ã‚¢ãƒ¼ãƒ«"]),
    ("LG", ["LG", "ã‚¨ãƒ«ã‚¸ãƒ¼"]),
    ("Samsung", ["SAMSUNG", "ã‚µãƒ ã‚¹ãƒ³"]),
    ("SANYO", ["SANYO", "ä¸‰æ´‹"]),
    ("BALMUDA", ["BALMUDA", "ãƒãƒ«ãƒŸãƒ¥ãƒ¼ãƒ€"]),
    ("IRIS OHYAMA", ["IRIS OHYAMA", "IRISOHYAMA", "ã‚¢ã‚¤ãƒªã‚¹ã‚ªãƒ¼ãƒ¤ãƒ"]),
    ("DAIKIN", ["DAIKIN", "ãƒ€ã‚¤ã‚­ãƒ³"]),
    ("AQUA", ["AQUA", "ã‚¢ã‚¯ã‚¢"]),
    ("Panasonic National", ["NATIONAL", "ãƒŠã‚·ãƒ§ãƒŠãƒ«"]),  # æ—§å
]

def _parse_maker(up_text: str) -> str:
    for canon, aliases in _MAKER_TABLE:
        if any(a in up_text for a in [al.upper() for al in aliases]):
            return canon
    return ""

# ---- è£½é€ ç•ªå·ï¼šãƒ‘ã‚¿ãƒ¼ãƒ³æ‹¡å¼µ ----
_SERIAL_LABEL_PATTERNS = [
    r'(?:S\/?\s*N|SER(?:IAL)?\s*NO\.?|SER\s*NO\.?|SNO\.?)',
    r'(?:è£½é€ ç•ªå·|è£½ç•ª|è£½é€ NO\.?|è£½é€ No\.?|è£½é€ â„–|è£½å“ç•ªå·)',
    r'(?:ç®¡ç†ç•ªå·|æœ¬ä½“ç•ªå·|æœ¬ä½“No\.?)',
    r'(?:NO\.|No\.)',
]
def _parse_serial(lines):
    up_lines = [ln.upper() for ln in lines]
    # ãƒ©ãƒ™ãƒ«ä»˜ãï¼šè¡Œã”ã¨ã«è¦‹ã‚‹ï¼ˆèª¤è·¨ãé˜²æ­¢ï¼‰
    for ln in up_lines:
        if any(re.search(p, ln) for p in _SERIAL_LABEL_PATTERNS):
            m = re.search(r'(?:' + "|".join(_SERIAL_LABEL_PATTERNS) + r')\s*[:ï¼š\-]?\s*([A-Z0-9\- ]{4,})', ln)
            if m:
                cand = re.sub(r'\s+', '', m.group(1)).strip('-')
                cand = _fix_confusions_for_serial(cand)
                # é€£ç¶šè¨˜å·ã ã‚‰ã‘ç­‰ã‚’é™¤å¤–
                if 6 <= len(cand) <= 24 and re.search(r'[A-Z]', cand) and re.search(r'\d', cand):
                    return cand
                if 8 <= len(cand) <= 20 and cand.isdigit():
                    return cand
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ©ãƒ™ãƒ«è¿‘å‚ã§è‹±æ•°é•·ã‚
    for ln in up_lines:
        if any(k in ln for k in ["SN", "SERIAL", "NO", "è£½é€ ", "è£½ç•ª"]):
            toks = re.findall(r'\b[A-Z0-9][A-Z0-9\-]{5,24}\b', ln)
            toks = [t.strip('-') for t in toks]
            for t in toks:
                tt = _fix_confusions_for_serial(t)
                if any(c.isalpha() for c in tt) and any(c.isdigit() for c in tt):
                    return tt
    return ""

# ---- å‹ç•ªï¼šãƒ©ãƒ™ãƒ«å„ªå…ˆï¼‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° ----
# NGèªï¼ˆå‹ç•ªã¨ã—ã¦å‡ºãŸã‚‰é™¤å¤–ï¼‰
_BAD_TOKENS = {
    "WARNING","CAUTION","JAPAN","WASHER","DRYER","REFRIGERATOR","INVERTER",
    "AC","DC","VOLT","HERTZ","HZ","W","KW","MM","CM","KG",
    "PANASONIC","HITACHI","TOSHIBA","SHARP","SONY","MITSUBISHI","HISENSE","HAIER","SAMSUNG","AQUA","SANYO","DAIKIN","IRIS","OHYAMA",
}
def _score_model_token(t: str) -> int:
    s = 0
    if '-' in t: s += 3
    if any(c.isalpha() for c in t) and any(c.isdigit() for c in t): s += 3
    if 3 <= len(t) <= 18: s += 2
    if re.search(r'^\w+-\w+', t): s += 2  # ä¾‹ï¼šNA-VXã€BD-S ç­‰
    return s

def _parse_model(lines, serial: str):
    up_all = " ".join([ln.upper() for ln in lines])

    # 1) ãƒ©ãƒ™ãƒ«ä»˜ãæŠ½å‡ºï¼ˆå¼·ï¼‰
    m = re.search(r'(?:å‹ç•ª|å‹å¼|å½¢å¼|å½¢å|MODEL(?:\s*NO\.?)?|MOD\.?|å“ç•ª|è£½å“å‹ç•ª|å½¢å¼å)\s*[:ï¼š\-]?\s*([A-Z0-9][A-Z0-9\-_\/\.]{2,24})', up_all)
    if m:
        tok = m.group(1)
        tok = _fix_confusions_for_model(tok)
        if tok not in _BAD_TOKENS:
            return tok

    # 2) è¡Œå˜ä½ã§å€™è£œåé›†â†’ã‚¹ã‚³ã‚¢æœ€å¤§ã‚’æ¡ç”¨
    cands = []
    for ln in [ln.upper() for ln in lines]:
        for t in re.findall(r'\b[A-Z][A-Z0-9\-_\/\.]{2,24}\b', ln):
            if t in _BAD_TOKENS: 
                continue
            if serial and t == serial:
                continue
            if re.fullmatch(r'\d{3,}', t):  # æ•°å­—ã ã‘
                continue
            t_fixed = _fix_confusions_for_model(t)
            score = _score_model_token(t_fixed)
            if score >= 4:
                cands.append((score, t_fixed))
    if cands:
        cands.sort(reverse=True)
        return cands[0][1]
    return ""

# ---- ã¾ã¨ã‚é–¢æ•°ï¼šOCRãƒ†ã‚­ã‚¹ãƒˆ â†’ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ----
def extract_fields_from_text(text: str) -> dict:
    if not text:
        return {"maker":"", "model":"", "serial":"", "year":""}
    lines = _split_lines(text)
    up_text = _normalize(text).upper()

    maker  = _parse_maker(up_text)
    serial = _parse_serial(lines)
    model  = _parse_model(lines, serial)
    year   = _parse_year(text)

    return {"maker": maker, "model": model, "serial": serial, "year": year}

# ---------------- â‘  ã‚¹ãƒãƒ›ã®ã‚«ãƒ¡ãƒ©ã‹ã‚‰è¤‡æ•°å›æ’®å½± ----------------
st.subheader("â‘  ãƒ©ãƒ™ãƒ«æ’®å½±ï¼ˆå¿…è¦ãªã ã‘è¤‡æ•°å›ï¼‰")

img_file = st.camera_input(
    "åˆ¥é¢ãƒ»åˆ¥ãƒ©ãƒ™ãƒ«ã‚’æ’®ã£ãŸã‚‰ã€ã“ã®å†™çœŸã‚’è¿½åŠ ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚",
    key=f"cam_{st.session_state['cam_key']}"
)

c1, c2, c3 = st.columns(3)
with c1:
    add_clicked = st.button("ã“ã®å†™çœŸã‚’è¿½åŠ ", disabled=(img_file is None))
with c2:
    remove_last = st.button("æœ€å¾Œã®å†™çœŸã‚’å‰Šé™¤", disabled=(len(st.session_state["shots"]) == 0))
with c3:
    clear_all = st.button("å…¨æ¶ˆå»", disabled=(len(st.session_state["shots"]) == 0))

if add_clicked and img_file is not None:
    img = Image.open(img_file)
    img = ImageOps.exif_transpose(img)  # ã‚¹ãƒãƒ›ã®å›è»¢è£œæ­£
    np_img = np.array(img.convert("RGB"))
    with st.spinner("OCRä¸­...ï¼ˆåˆå›ã¯ãƒ¢ãƒ‡ãƒ«å–å¾—ã§å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰"):
        res = reader.readtext(np_img)  # [(box, text, conf), ...]
    ocr_text = "\n".join([r[1] for r in res])
    st.session_state["shots"].append({"img": img, "ocr": ocr_text})

if remove_last and st.session_state["shots"]:
    st.session_state["shots"].pop()
    st.session_state["cam_key"] += 1
    st.rerun()

if clear_all and st.session_state["shots"]:
    st.session_state["shots"].clear()
    st.session_state["cam_key"] += 1
    st.rerun()

st.write(f"ç¾åœ¨ã®æ’®å½±æšæ•°ï¼š**{len(st.session_state['shots'])}** æš")
if st.session_state["shots"]:
    for idx, shot in enumerate(st.session_state["shots"], start=1):
        st.image(shot["img"], caption=f"æ’®å½± {idx}", use_container_width=True)
        st.text_area(f"OCRçµæœ {idx}", shot["ocr"], height=100, key=f"ocr_{idx}")

# ---------------- â‘¡-0 OCRè‡ªå‹•æŠ½å‡ºï¼ˆå…¥åŠ›æ¬„ã®å‰ã«å®Ÿè¡Œ = é‡è¦ï¼‰ ----------------
st.subheader("â‘¡-0 OCR è‡ªå‹•æŠ½å‡ºï¼ˆä»»æ„ï¼‰")
st.checkbox("OCR è‡ªå‹•å…¥åŠ›ã‚’æœ‰åŠ¹ã«ã™ã‚‹ï¼ˆç©ºæ¬„ã®ã¿è‡ªå‹•åæ˜ ï¼‰", key="autofill_enabled")

aggregated_text = "\n---\n".join([s["ocr"] for s in st.session_state["shots"]]) if st.session_state["shots"] else ""
suggest = extract_fields_from_text(aggregated_text) if aggregated_text else {"maker": "", "model": "", "serial": "", "year": ""}

# ç©ºæ¬„ã®ã¿è‡ªå‹•åæ˜ ï¼ˆã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆæç”»å‰ã« state ã‚’æ›´æ–°ã™ã‚‹ï¼‰
if st.session_state["autofill_enabled"] and aggregated_text:
    for field in ("maker", "model", "serial", "year"):
        if not st.session_state[field] and suggest.get(field):
            st.session_state[field] = suggest[field]

with st.expander("OCRçµ±åˆãƒ†ã‚­ã‚¹ãƒˆï¼†æŠ½å‡ºå€™è£œã®ç¢ºèª", expanded=False):
    st.text_area("çµ±åˆOCRãƒ†ã‚­ã‚¹ãƒˆ", aggregated_text, height=180)
    st.write("æŠ½å‡ºå€™è£œï¼ˆä¸Šæ›¸ãã—ãŸã„å ´åˆã¯ä¸‹ã®ãƒœã‚¿ãƒ³ã§åæ˜ ã§ãã¾ã™ï¼‰")
    st.json(suggest)
    if st.button("å€™è£œã§å…¥åŠ›æ¬„ã‚’ä¸Šæ›¸ãã™ã‚‹"):
        for field in ("maker", "model", "serial", "year"):
            st.session_state[field] = suggest.get(field, "")
        st.success("å€™è£œã§å…¥åŠ›æ¬„ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
        st.rerun()

# ---------------- â‘¡ å›åæƒ…å ±ã®å…¥åŠ›ï¼ˆæ‰‹å…¥åŠ›ï¼‰ ----------------
st.subheader("â‘¡ å›åæƒ…å ±ã®å…¥åŠ›ï¼ˆæ‰‹å…¥åŠ›ï¼‰")

# å›åæ—¥ï¼ˆå€¤ã¯ st.session_state["pickup_date"] ã«è‡ªå‹•ã§å…¥ã‚‹ï¼‰
st.date_input("å›åæ—¥", key="pickup_date")


WAREHOUSES = [
    "æœ¬ç¤¾å€‰åº«ï¼ˆæ±äº¬ï¼‰", "æ±æ—¥æœ¬ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆä»™å°ï¼‰",
    "è¥¿æ—¥æœ¬ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆå¤§é˜ªï¼‰", "ä¹å·ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆç¦å²¡ï¼‰",
    "ãã®ä»–ï¼ˆæ‰‹å…¥åŠ›ï¼‰",
]
st.selectbox(
    "å€‰åº«ã‚’é¸æŠ",
    options=WAREHOUSES,
    index=WAREHOUSES.index(st.session_state["warehouse_choice"]) if st.session_state["warehouse_choice"] in WAREHOUSES else 0,
    key="warehouse_choice",
)
if st.session_state["warehouse_choice"] == "ãã®ä»–ï¼ˆæ‰‹å…¥åŠ›ï¼‰":
    st.text_input("å€‰åº«åã‚’å…¥åŠ›", key="warehouse_other")

warehouse = (
    st.session_state["warehouse_other"]
    if st.session_state["warehouse_choice"] == "ãã®ä»–ï¼ˆæ‰‹å…¥åŠ›ï¼‰"
    else st.session_state["warehouse_choice"]
)

# ã“ã“ã«è‡ªå‹•åæ˜ æ¸ˆã¿ã®å€¤ãŒå…¥ã£ã¦ãã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‰‹ä¿®æ­£ãŒå¯èƒ½ï¼‰
st.text_input("ãƒ¡ãƒ¼ã‚«ãƒ¼", key="maker")
st.text_input("å‹ç•ª", key="model")
st.text_input("è£½é€ ç•ªå·", key="serial")
st.text_input("å¹´å¼", key="year")
st.text_area("å‚™è€ƒ", key="note")

# ---------------- â‘¢ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä¿å­˜ï¼ˆA1:G1å›ºå®šè¿½è¨˜ï¼‰ ----------------
st.subheader("â‘¢ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä¿å­˜")
can_save = sheet is not None and st.session_state["pickup_date"] and (warehouse or st.session_state["maker"] or st.session_state["model"])
if st.button("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜", disabled=not can_save):
    try:
        payload = [
            str(st.session_state["pickup_date"]),  # A: å›åæ—¥
            warehouse,                              # B: å›åå€‰åº«
            st.session_state["maker"],              # C: ãƒ¡ãƒ¼ã‚«ãƒ¼
            st.session_state["model"],              # D: å‹ç•ª
            st.session_state["serial"],             # E: è£½é€ ç•ªå·
            st.session_state["year"],               # F: å¹´å¼
            st.session_state["note"],               # G: å‚™è€ƒ
        ]
        sheet.append_row(
            payload,
            value_input_option="USER_ENTERED",
            table_range="A1:G1",
        )
        st.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«åæ˜ ã—ã¾ã—ãŸï¼")

        # â˜…ã“ã“ã‚’ç½®ãæ›ãˆï¼šæ¬¡ã®å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ«ã§åˆæœŸåŒ–ã™ã‚‹ãƒ•ãƒ©ã‚°ã ã‘ç«‹ã¦ã‚‹
        st.session_state["_reset_pending"] = True
        st.rerun()
    except Exception as e:
        st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ¥ç¶š/æ›¸ãè¾¼ã¿ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è©³ç´°: {e}")

# ---------------- æ’®å½±ãƒ‡ãƒ¼ã‚¿ã ã‘ãƒªã‚»ãƒƒãƒˆ ----------------
if st.button("æ’®å½±ãƒ‡ãƒ¼ã‚¿ã ã‘ãƒªã‚»ãƒƒãƒˆ"):
    st.session_state["shots"].clear()
    st.session_state["cam_key"] += 1
    st.success("æ’®å½±ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")